{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da7947c-7afd-469e-82bc-51b291b720e6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Pipeline ETL Automatisé: CSV et API vers MySQL\n",
    "\n",
    "Ce notebook implémente un pipeline ETL complet qui:\n",
    "1. Extrait des données depuis deux fichiers CSV (orders.csv et details.csv)\n",
    "2. Extrait des données supplémentaires depuis une API publique\n",
    "3. Transforme et nettoie les données\n",
    "4. Charge les données dans une base de données MySQL\n",
    "5. Automatise le processus avec des fonctions réutilisables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71cf1b7-7976-41d8-8e56-929e540dc99c",
   "metadata": {},
   "source": [
    "### Configuration initiale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1bc31-f1bb-4ed4-84be-7092149daa0d",
   "metadata": {},
   "source": [
    "Ici, je prépare le terrain : \n",
    "\n",
    "j’importe les bibliothèques, je récupère les infos de connexion depuis un fichier *.env*, et je vérifie que je peux bien \n",
    "me connecter à ma base de données MySQL. Si tout se passe bien, un petit message de succès s’affiche. Sinon, j’ai une\n",
    "erreur claire pour savoir ce qui cloche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04f276e4-71a1-430e-b025-f11a0b8ad62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion à MySQL réussie.\n"
     ]
    }
   ],
   "source": [
    "# !pip install pymysql pandas sqlalchemy python-dotenv requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, exc\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Chargement des variables d'environnement\n",
    "load_dotenv('config/.env')\n",
    "\n",
    "# Récupération des infos de connexion MySQL\n",
    "user = os.getenv('MYSQL_USER', 'root')\n",
    "password = os.getenv('MYSQL_PASSWORD', '')\n",
    "host = os.getenv('MYSQL_HOST', 'localhost')\n",
    "port = os.getenv('MYSQL_PORT', '3306')\n",
    "db = os.getenv('MYSQL_DB', 'etl_project')\n",
    "\n",
    "# Création de la connexion\n",
    "engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:{port}/{db}')\n",
    "\n",
    "# Test de connexion\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        print(\"Connexion à MySQL réussie.\")\n",
    "except exc.SQLAlchemyError as e:\n",
    "    print(f\"Erreur de connexion : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d79119-95ca-49fb-92de-4ff2855be872",
   "metadata": {},
   "source": [
    "#### Remarque\n",
    "\n",
    "Il faut savoir que avant que ce code ne marche, il vous faut avoir créer votre base de donnée et le nommer **etl_project** avec Mysql."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce14febd-98c2-4f93-b636-a8b721f8cb37",
   "metadata": {},
   "source": [
    "### D'abord c’est quoi un processus ETL ?\n",
    "\n",
    "**ETL** signifie **Extract – Transform – Load**.\n",
    "\n",
    "C’est un processus classique utilisé en data engineering pour manipuler des données :\n",
    "\n",
    "***Extract*** : on récupère les données depuis une source (fichier CSV, base de données, API, etc.).\n",
    "\n",
    "***Transform***: on nettoie, filtre, reformate ou enrichit les données pour qu’elles soient exploitables.\n",
    "\n",
    "***Load*** : on charge les données transformées dans une base de données ou un entrepôt de données pour analyse ou visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26373b64-a710-49c0-9fbb-460c9220d187",
   "metadata": {},
   "source": [
    "### Extraction des données CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c9e0d-7349-4905-aad5-0f9ce53bb270",
   "metadata": {},
   "source": [
    "On commence par extraire les fichiers CSV contenant les commandes et leurs détails, puis j’affiche un aperçu du contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b650d59f-90b3-4845-8b5b-9a89c66e11b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données extraites depuis data/orders.csv\n",
      "Données extraites depuis data/details.csv\n",
      "\n",
      "Commandes :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-26055</td>\n",
       "      <td>10-03-2018</td>\n",
       "      <td>Harivansh</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Mathura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-25993</td>\n",
       "      <td>03-02-2018</td>\n",
       "      <td>Madhav</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-25973</td>\n",
       "      <td>24-01-2018</td>\n",
       "      <td>Madan Mohan</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Mathura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-25923</td>\n",
       "      <td>27-12-2018</td>\n",
       "      <td>Gopal</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-25757</td>\n",
       "      <td>21-08-2018</td>\n",
       "      <td>Vishakha</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order ID  Order Date CustomerName           State     City\n",
       "0  B-26055  10-03-2018    Harivansh   Uttar Pradesh  Mathura\n",
       "1  B-25993  03-02-2018       Madhav           Delhi    Delhi\n",
       "2  B-25973  24-01-2018  Madan Mohan   Uttar Pradesh  Mathura\n",
       "3  B-25923  27-12-2018        Gopal     Maharashtra   Mumbai\n",
       "4  B-25757  21-08-2018     Vishakha  Madhya Pradesh   Indore"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Détails :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>PaymentMode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-25681</td>\n",
       "      <td>1096</td>\n",
       "      <td>658</td>\n",
       "      <td>7</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Electronic Games</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-26055</td>\n",
       "      <td>5729</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>EMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-25955</td>\n",
       "      <td>2927</td>\n",
       "      <td>146</td>\n",
       "      <td>8</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>EMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-26093</td>\n",
       "      <td>2847</td>\n",
       "      <td>712</td>\n",
       "      <td>8</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Printers</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-25602</td>\n",
       "      <td>2617</td>\n",
       "      <td>1151</td>\n",
       "      <td>4</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Phones</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order ID  Amount  Profit  Quantity     Category      Sub-Category  \\\n",
       "0  B-25681    1096     658         7  Electronics  Electronic Games   \n",
       "1  B-26055    5729      64        14    Furniture            Chairs   \n",
       "2  B-25955    2927     146         8    Furniture         Bookcases   \n",
       "3  B-26093    2847     712         8  Electronics          Printers   \n",
       "4  B-25602    2617    1151         4  Electronics            Phones   \n",
       "\n",
       "   PaymentMode  \n",
       "0          COD  \n",
       "1          EMI  \n",
       "2          EMI  \n",
       "3  Credit Card  \n",
       "4  Credit Card  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_csv_data(file_path):\n",
    "    \"\"\"Lecture d'un fichier CSV et retour d'un DataFrame\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Données extraites depuis {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction : {e}\")\n",
    "        return None\n",
    "# Extraction des données CSV\n",
    "orders_df = extract_csv_data('data/orders.csv')\n",
    "details_df = extract_csv_data('data/details.csv')\n",
    "# Aperçus rapides\n",
    "print(\"\\nCommandes :\")\n",
    "display(orders_df.head())\n",
    "print(\"\\nDétails :\")\n",
    "display(details_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f11c90-0896-4564-95c8-099425afc12e",
   "metadata": {},
   "source": [
    "### Extraction des données depuis une API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aa8f1bbd-b5d4-4a5e-bcfc-c1618ed1904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pays extraits depuis l'API.\n",
      "\n",
      "Aperçu des données de l'API :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>region</th>\n",
       "      <th>subregion</th>\n",
       "      <th>population</th>\n",
       "      <th>currency</th>\n",
       "      <th>timezones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eritrea</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>5352000</td>\n",
       "      <td>ERN</td>\n",
       "      <td>UTC+03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cameroon</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Middle Africa</td>\n",
       "      <td>26545864</td>\n",
       "      <td>XAF</td>\n",
       "      <td>UTC+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southeast Europe</td>\n",
       "      <td>621718</td>\n",
       "      <td>EUR</td>\n",
       "      <td>UTC+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fiji</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>896444</td>\n",
       "      <td>FJD</td>\n",
       "      <td>UTC+12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tunisia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>11818618</td>\n",
       "      <td>TND</td>\n",
       "      <td>UTC+01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name   region         subregion  population currency  timezones\n",
       "0      Eritrea   Africa    Eastern Africa     5352000      ERN  UTC+03:00\n",
       "1     Cameroon   Africa     Middle Africa    26545864      XAF  UTC+01:00\n",
       "2   Montenegro   Europe  Southeast Europe      621718      EUR  UTC+01:00\n",
       "3         Fiji  Oceania         Melanesia      896444      FJD  UTC+12:00\n",
       "4      Tunisia   Africa   Northern Africa    11818618      TND  UTC+01:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_api_data(limit=None):\n",
    "    \"\"\"Extrait des données de base sur les pays depuis l'API REST Countries\"\"\"\n",
    "    url = \"https://restcountries.com/v3.1/all\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        countries_data = []\n",
    "        for country in data[:limit]:  # On limite si besoin\n",
    "            name = country.get('name', {}).get('common', 'Inconnu')\n",
    "            region = country.get('region', 'Inconnu')\n",
    "            subregion = country.get('subregion', 'Inconnu')\n",
    "            population = country.get('population', 0)\n",
    "            currency_keys = list(country.get('currencies', {}).keys())\n",
    "            currency = currency_keys[0] if currency_keys else 'Inconnu'\n",
    "            timezones = ', '.join(country.get('timezones', [])) if country.get('timezones') else 'Inconnu'\n",
    "\n",
    "            countries_data.append({\n",
    "                'country_name': name,\n",
    "                'region': region,\n",
    "                'subregion': subregion,\n",
    "                'population': population,\n",
    "                'currency': currency,\n",
    "                'timezones': timezones\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(countries_data)\n",
    "        print(f\"{len(df)} pays extraits depuis l'API.\")\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur réseau ou API : {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur inattendue : {e}\")\n",
    "    \n",
    "    return pd.DataFrame()  # Retourne un DataFrame vide si erreur\n",
    "# test Extraction des données\n",
    "countries_df = extract_api_data(limit=10)  \n",
    "print(\"\\nAperçu des données de l'API :\")\n",
    "display(countries_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94382e-8c8b-4798-b757-dcf2036eab7e",
   "metadata": {},
   "source": [
    "### Transformation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a6693-0f55-4586-a831-573bf29cd1cd",
   "metadata": {},
   "source": [
    "Dans notre logique ETL (Extract – Transform – Load), cette étape correspond à la transformation : on prend les données brutes, on les fusionne, on nettoie, on enrichit avec des infos externes (ici, les pays), et on ajoute des indicateurs utiles pour l’analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d69547f1-a7e7-4a33-885e-938760c0210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données transformées avec succès\n",
      "\n",
      "Aperçu des données finales :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>PaymentMode</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Important Order</th>\n",
       "      <th>Year Month</th>\n",
       "      <th>region</th>\n",
       "      <th>subregion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-26055</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Harivansh</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Mathura</td>\n",
       "      <td>5729</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>EMI</td>\n",
       "      <td>1.12</td>\n",
       "      <td>Oui</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>Inconnu</td>\n",
       "      <td>Inconnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-26055</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Harivansh</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Mathura</td>\n",
       "      <td>671</td>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Phones</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>16.99</td>\n",
       "      <td>Oui</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>Inconnu</td>\n",
       "      <td>Inconnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-26055</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Harivansh</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Mathura</td>\n",
       "      <td>443</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Saree</td>\n",
       "      <td>COD</td>\n",
       "      <td>2.48</td>\n",
       "      <td>Oui</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>Inconnu</td>\n",
       "      <td>Inconnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-26055</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Harivansh</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Mathura</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>UPI</td>\n",
       "      <td>12.28</td>\n",
       "      <td>Non</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>Inconnu</td>\n",
       "      <td>Inconnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-26055</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Harivansh</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Mathura</td>\n",
       "      <td>227</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Stole</td>\n",
       "      <td>COD</td>\n",
       "      <td>21.15</td>\n",
       "      <td>Non</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>Inconnu</td>\n",
       "      <td>Inconnu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order ID Order Date CustomerName          State     City  Amount  Profit  \\\n",
       "0  B-26055 2018-10-03    Harivansh  Uttar Pradesh  Mathura    5729      64   \n",
       "1  B-26055 2018-10-03    Harivansh  Uttar Pradesh  Mathura     671     114   \n",
       "2  B-26055 2018-10-03    Harivansh  Uttar Pradesh  Mathura     443      11   \n",
       "3  B-26055 2018-10-03    Harivansh  Uttar Pradesh  Mathura      57       7   \n",
       "4  B-26055 2018-10-03    Harivansh  Uttar Pradesh  Mathura     227      48   \n",
       "\n",
       "   Quantity     Category Sub-Category  PaymentMode  Profit Margin  \\\n",
       "0        14    Furniture       Chairs          EMI           1.12   \n",
       "1         9  Electronics       Phones  Credit Card          16.99   \n",
       "2         1     Clothing        Saree          COD           2.48   \n",
       "3         2     Clothing        Shirt          UPI          12.28   \n",
       "4         5     Clothing        Stole          COD          21.15   \n",
       "\n",
       "  Important Order Year Month   region subregion  \n",
       "0             Oui    2018-10  Inconnu   Inconnu  \n",
       "1             Oui    2018-10  Inconnu   Inconnu  \n",
       "2             Oui    2018-10  Inconnu   Inconnu  \n",
       "3             Non    2018-10  Inconnu   Inconnu  \n",
       "4             Non    2018-10  Inconnu   Inconnu  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_data(orders_df, details_df, countries_df):\n",
    "    \"\"\"\n",
    "    Fusionne et prépare les données pour l'analyse :\n",
    "    - jointure commandes + détails\n",
    "    - nettoyage et enrichissement\n",
    "    - indicateurs utiles ajoutés\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # On commence par fusionner les commandes et les détails\n",
    "        merged_df = pd.merge(orders_df, details_df, on='Order ID', how='inner')\n",
    "        \n",
    "        # Conversion des dates : on transforme le champ texte en datetime exploitable\n",
    "        merged_df['Order Date'] = pd.to_datetime(merged_df['Order Date'], errors='coerce')\n",
    "        \n",
    "        # Calcul du pourcentage de profit\n",
    "        merged_df['Profit Margin'] = (merged_df['Profit'] / merged_df['Amount'] * 100).round(2)\n",
    "        \n",
    "        # Marquage des commandes \"importantes\" selon le montant\n",
    "        seuil = merged_df['Amount'].quantile(0.75)\n",
    "        merged_df['Important Order'] = np.where(merged_df['Amount'] > seuil, 'Oui', 'Non')\n",
    "        \n",
    "        # Ajout d'une colonne \"Année-Mois\" pour faciliter les analyses temporelles\n",
    "        merged_df['Year Month'] = merged_df['Order Date'].dt.to_period('M')\n",
    "        \n",
    "        # On enrichit avec les infos pays via une jointure sur le champ \"State\"\n",
    "        # (Remarque : dans la vraie vie, on ferait une jointure plus précise avec les bons codes pays)\n",
    "        merged_df = pd.merge(\n",
    "            merged_df,\n",
    "            countries_df[['country_name', 'region', 'subregion']],\n",
    "            left_on='State',\n",
    "            right_on='country_name',\n",
    "            how='left'\n",
    "        ).drop(columns=['country_name'])  # Pas besoin de garder ce champ ensuite\n",
    "        \n",
    "        # On remplit les régions manquantes par défaut\n",
    "        merged_df['region'] = merged_df['region'].fillna('Inconnu')\n",
    "        merged_df['subregion'] = merged_df['subregion'].fillna('Inconnu')\n",
    "        \n",
    "        print(\"Données transformées avec succès\")\n",
    "        return merged_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Problème pendant la transformation : {e}\")\n",
    "        return None\n",
    "\n",
    "# test Transformation des données\n",
    "transformed_df = transform_data(orders_df, details_df, countries_df)\n",
    "print(\"\\nAperçu des données finales :\")\n",
    "display(transformed_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584e4bf-5b1b-44a0-bf90-4a569479e045",
   "metadata": {},
   "source": [
    "### Chargement des données dans MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de818e8f-259d-4e82-accb-9097fa8af71b",
   "metadata": {},
   "source": [
    "Cette fonction prend un DataFrame, un nom de table, et un moteur SQLAlchemy pour envoyer les données dans une base MySQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e7822ed-6a04-4ce9-9c09-278942f2e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "def load_data_to_mysql(df, table_name, engine):\n",
    "    \"\"\"Charge les données dans MySQL en gérant automatiquement la création des tables\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # Vérification si la table existe déjà\n",
    "            table_exists = conn.execute(\n",
    "                text(f\"SHOW TABLES LIKE '{table_name}'\")\n",
    "            ).fetchone()\n",
    "            \n",
    "            if not table_exists:\n",
    "                # Création de la table basée sur le DataFrame\n",
    "                print(f\"Création de la table '{table_name}'...\")\n",
    "                df.head(0).to_sql(\n",
    "                    name=table_name,\n",
    "                    con=engine,\n",
    "                    index=False,\n",
    "                    if_exists='fail',  # Échoue si la table existe déjà\n",
    "                    chunksize=1000\n",
    "                )\n",
    "                print(f\"Table '{table_name}' créée avec succès\")\n",
    "            else:\n",
    "                print(f\"Table '{table_name}' existe déjà, ajout des données...\")\n",
    "            \n",
    "            # Chargement des données\n",
    "            df.to_sql(\n",
    "                name=table_name,\n",
    "                con=engine,\n",
    "                index=False,\n",
    "                if_exists='append',  # Ajoute aux données existantes\n",
    "                chunksize=1000,\n",
    "                method='multi'\n",
    "            )\n",
    "            \n",
    "            print(f\"Données chargées avec succès dans '{table_name}'\")\n",
    "            \n",
    "            # Vérification\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "            count_before = result.fetchone()[0] - len(df)\n",
    "            count_after = count_before + len(df)\n",
    "            print(f\"Nombre d'enregistrements: {count_before} → {count_after} (+{len(df)})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement: {e}\")\n",
    "        raise\n",
    "\n",
    "##on ajoute un schéma précis selon le nom de la table. Cela donne plus de contrôle sur la structure SQL\n",
    "def load_data_to_mysql_typed(df, table_name, engine):\n",
    "    \"\"\"Charge les données avec un schéma spécifique, sans doublons\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # Vérification si la table existe\n",
    "            table_exists = conn.execute(\n",
    "                text(f\"SHOW TABLES LIKE '{table_name}'\")\n",
    "            ).fetchone()\n",
    "\n",
    "            if not table_exists:\n",
    "                print(f\"Création de la table typée '{table_name}'...\")\n",
    "\n",
    "                if table_name == 'orders_details':\n",
    "                    create_sql = \"\"\"\n",
    "                    CREATE TABLE orders_details (\n",
    "                        `Order ID` VARCHAR(50) PRIMARY KEY,\n",
    "                        `Order Date` DATETIME,\n",
    "                        `CustomerName` VARCHAR(100),\n",
    "                        `State` VARCHAR(50),\n",
    "                        `City` VARCHAR(50),\n",
    "                        `Amount` DECIMAL(10, 2),\n",
    "                        `Profit` DECIMAL(10, 2),\n",
    "                        `Quantity` INT,\n",
    "                        `Category` VARCHAR(50),\n",
    "                        `Sub-Category` VARCHAR(50),\n",
    "                        `PaymentMode` VARCHAR(50),\n",
    "                        `Profit Margin` DECIMAL(5, 2),\n",
    "                        `Important Order` VARCHAR(3),\n",
    "                        `Year Month` VARCHAR(7),\n",
    "                        `region` VARCHAR(50),\n",
    "                        `subregion` VARCHAR(50)\n",
    "                    ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci\n",
    "                    \"\"\"\n",
    "                elif table_name == 'countries':\n",
    "                    create_sql = \"\"\"\n",
    "                    CREATE TABLE countries (\n",
    "                        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                        country_name VARCHAR(100),\n",
    "                        region VARCHAR(50),\n",
    "                        subregion VARCHAR(50),\n",
    "                        population BIGINT,\n",
    "                        currency VARCHAR(10),\n",
    "                        timezones VARCHAR(50)\n",
    "                    ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci\n",
    "                    \"\"\"\n",
    "                else:\n",
    "                    create_sql = None\n",
    "\n",
    "                if create_sql:\n",
    "                    conn.execute(text(create_sql))\n",
    "                    print(f\"Table '{table_name}' créée avec le schéma spécifique\")\n",
    "                else:\n",
    "                    df.head(0).to_sql(\n",
    "                        name=table_name,\n",
    "                        con=engine,\n",
    "                        index=False,\n",
    "                        if_exists='fail'\n",
    "                    )\n",
    "                    print(f\"Table '{table_name}' créée avec schéma automatique\")\n",
    "\n",
    "            # Étape clé : suppression des doublons dans df\n",
    "            if 'Order ID' in df.columns:\n",
    "                # Lecture des identifiants existants\n",
    "                existing_ids = pd.read_sql(f\"SELECT `Order ID` FROM {table_name}\", con=engine)\n",
    "                before_filter = len(df)\n",
    "                df = df[~df['Order ID'].isin(existing_ids['Order ID'])]\n",
    "                after_filter = len(df)\n",
    "                print(f\"{before_filter - after_filter} doublons détectés et ignorés.\")\n",
    "                \n",
    "                if df.empty:\n",
    "                    print(\"Aucune nouvelle donnée à insérer.\")\n",
    "                    return\n",
    "\n",
    "            # Insertion finale\n",
    "            df.to_sql(\n",
    "                name=table_name,\n",
    "                con=engine,\n",
    "                index=False,\n",
    "                if_exists='append',\n",
    "                chunksize=1000,\n",
    "                method='multi'\n",
    "            )\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "            count = result.fetchone()[0]\n",
    "            print(f\"Total d'enregistrements dans '{table_name}': {count}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39477bae-9e2e-4124-8c93-d6cd61bafef4",
   "metadata": {},
   "source": [
    "### Automatisation complète du pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53224063-0929-4430-8617-a3af6ae10649",
   "metadata": {},
   "source": [
    "Le petit chef d’orchestre suivant va lancer tout le processus ETL, étape par étape :\n",
    "\n",
    "**1.Démarrage**\n",
    "Il affiche que le pipeline commence, et il lance un chronomètre pour mesurer combien de temps tout le processus va prendre.\n",
    "\n",
    "**2.Extraction**\n",
    "Il va chercher les données brutes :\n",
    "depuis le fichier orders.csv\n",
    "depuis le fichier details.csv\n",
    "et via une API pour récupérer les données des pays\n",
    "\n",
    "**3.Transformation**\n",
    "Il nettoie et transforme les données extraites : il fusionne les tableaux, calcule les marges, ajoute des indicateurs utiles, et associe les données aux pays.\n",
    "\n",
    "**4.Chargement**\n",
    "Une fois les données prêtes, il les insère dans la base MySQL :\n",
    "les données transformées vont dans la table orders_details\n",
    "les pays vont dans la table countries\n",
    "\n",
    "**5.Rapport final**\n",
    "Il affiche un message de succès avec le temps total mis pour exécuter le pipeline.\n",
    "\n",
    "Ce script te permet donc de tout faire d’un coup : extraire, transformer, charger sans devoir lancer chaque étape manuellement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c5bb7c26-3ad8-496c-90d5-ef9f457e26b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage du pipeline ETL...\n",
      "\n",
      "Étape 1: Extraction des données...\n",
      "Données extraites depuis data/orders.csv\n",
      "Données extraites depuis data/details.csv\n",
      "250 pays extraits depuis l'API.\n",
      "\n",
      "Étape 2: Transformation des données...\n",
      "Données transformées avec succès\n",
      "\n",
      "Étape 3: Chargement des données...\n",
      "Création de la table 'orders_details'...\n",
      "Table 'orders_details' créée avec succès\n",
      "Données chargées avec succès dans 'orders_details'\n",
      "Nombre d'enregistrements: 0 → 1500 (+1500)\n",
      "Création de la table 'countries'...\n",
      "Table 'countries' créée avec succès\n",
      "Données chargées avec succès dans 'countries'\n",
      "Nombre d'enregistrements: 0 → 250 (+250)\n",
      "\n",
      "Pipeline ETL terminé avec succès en 1.44 secondes\n"
     ]
    }
   ],
   "source": [
    "def run_etl_pipeline():\n",
    "    \"\"\"Exécute le pipeline ETL complet\"\"\"\n",
    "    print(\"Démarrage du pipeline ETL...\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Extraction\n",
    "    print(\"\\nÉtape 1: Extraction des données...\")\n",
    "    orders = extract_csv_data('data/orders.csv')\n",
    "    details = extract_csv_data('data/details.csv')\n",
    "    countries = extract_api_data()\n",
    "    \n",
    "    # Transformation\n",
    "    print(\"\\nÉtape 2: Transformation des données...\")\n",
    "    transformed_data = transform_data(orders, details, countries)\n",
    "    \n",
    "    # Chargement\n",
    "    print(\"\\nÉtape 3: Chargement des données...\")\n",
    "    if transformed_data is not None:\n",
    "        load_data_to_mysql(transformed_data, 'orders_details', engine)\n",
    "    if countries is not None:\n",
    "        load_data_to_mysql(countries, 'countries', engine)\n",
    "    \n",
    "    # Rapport final\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"\\nPipeline ETL terminé avec succès en {duration.total_seconds():.2f} secondes\")\n",
    "\n",
    "# Exécution du pipeline complet\n",
    "run_etl_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784fd0c2-da02-484f-8105-bfedb84af518",
   "metadata": {},
   "source": [
    "### Requêtes SQL de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeca510-3b92-4b98-8f07-b9dffe550048",
   "metadata": {},
   "source": [
    "La fonction advanced_validation() exécute des requêtes SQL pour vérifier les données dans les tables orders_details et countries. Elle récupère le nombre total de commandes, le chiffre d'affaires total, le profit total, les 5 catégories les plus rentables, et le nombre de pays enregistrés. Chaque requête est exécutée avec gestion d'erreurs, et les résultats sont affichés proprement à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "970019b1-99f3-4a52-a8de-68ac45f749ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VALIDATION AVANCÉE\n",
      " Commandes Total - Succès\n",
      " Ca Total - Succès\n",
      " Profit Total - Succès\n",
      " Top Categories - Succès\n",
      " Pays Total - Succès\n",
      "\n",
      "RÉSULTATS DE VALIDATION:\n",
      "- Commandes totales: 1500\n",
      "- CA total: 437771.00 €\n",
      "- Profit total: 36963.00 €\n",
      "- Pays référencés: 250\n",
      "\n",
      "Top Catégories:\n",
      "- Clothing: 13325.00 €\n",
      "- Electronics: 13162.00 €\n",
      "- Furniture: 10476.00 €\n"
     ]
    }
   ],
   "source": [
    "def advanced_validation():\n",
    "    \"\"\"Validation avancée avec gestion des erreurs par requête\"\"\"\n",
    "    validation_queries = {\n",
    "        'commandes_total': \"SELECT COUNT(*) FROM orders_details\",\n",
    "        'ca_total': \"SELECT ROUND(SUM(Amount), 2) FROM orders_details\",\n",
    "        'profit_total': \"SELECT ROUND(SUM(Profit), 2) FROM orders_details\",\n",
    "        'top_categories': \"\"\"\n",
    "            SELECT Category, ROUND(SUM(Profit), 2) as profit \n",
    "            FROM orders_details \n",
    "            GROUP BY Category \n",
    "            ORDER BY profit DESC \n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "        'pays_total': \"SELECT COUNT(*) FROM countries\"\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            print(\" VALIDATION AVANCÉE\")\n",
    "            \n",
    "            for name, query in validation_queries.items():\n",
    "                try:\n",
    "                    result = conn.execute(text(query))\n",
    "                    \n",
    "                    if name == 'top_categories':\n",
    "                        results[name] = result.fetchall()\n",
    "                    else:\n",
    "                        results[name] = result.fetchone()[0]\n",
    "                        \n",
    "                    print(f\" {name.replace('_', ' ').title()} - Succès\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\" {name.replace('_', ' ').title()} - Erreur: {str(e)[:50]}...\")\n",
    "                    results[name] = None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nErreur majeure: {e}\")\n",
    "        return None\n",
    "    # Affichage structuré des résultats\n",
    "    print(\"\\nRÉSULTATS DE VALIDATION:\")\n",
    "    print(f\"- Commandes totales: {results.get('commandes_total', 'N/A')}\")\n",
    "    print(f\"- CA total: {results.get('ca_total', 'N/A')} €\")\n",
    "    print(f\"- Profit total: {results.get('profit_total', 'N/A')} €\")\n",
    "    print(f\"- Pays référencés: {results.get('pays_total', 'N/A')}\")\n",
    "    if results.get('top_categories'):\n",
    "        print(\"\\nTop Catégories:\")\n",
    "        for cat, profit in results['top_categories']:\n",
    "            print(f\"- {cat}: {profit} €\")\n",
    "\n",
    "# Exécution\n",
    "advanced_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f6e03-5402-4565-9474-cbba8efce056",
   "metadata": {},
   "source": [
    "### Résumé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5c55f-9bec-4a04-b76d-40f5106264a6",
   "metadata": {},
   "source": [
    "Ce notebook met en œuvre un pipeline ETL complet qui extrait des données depuis des fichiers CSV et une API, les transforme, puis les charge dans une base de données MySQL. Le chargement est géré intelligemment pour éviter les erreurs de duplication. La création des tables peut se faire automatiquement à partir de la structure du DataFrame ou en définissant un schéma SQL précis. Un module de validation avancée permet ensuite de vérifier les agrégats clés (nombre total de commandes, chiffre d’affaires, bénéfices, etc.) ainsi que des insights comme les catégories les plus rentables.\n",
    "\n",
    "Ce pipeline est réutilisable pour tout autre jeu de données, à condition d’adapter les noms de colonnes, les règles de transformation, et les requêtes SQL de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa562e6d-0b9f-48d8-acec-0c8eaeed971e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
